{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code is adapted from CADDA and braincode\n",
    "from audioop import reverse\n",
    "from enum import auto\n",
    "from numbers import Real\n",
    "from operator import invert\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.interpolate import Rbf\n",
    "from scipy.spatial.transform import Rotation\n",
    "from sklearn.utils import check_random_state\n",
    "from torch.fft import fft, ifft\n",
    "from torch.nn.functional import dropout2d, pad, one_hot\n",
    "from torch.distributions import Normal\n",
    "from mne.filter import notch_filter\n",
    "from mne.channels.interpolation import _make_interpolation_matrix\n",
    "from mne.channels import make_standard_montage\n",
    "import matplotlib.pyplot as plt\n",
    "from ecgdetectors import Detectors\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "target_dir = 'subdiag'\n",
    "num_class = 23\n",
    "n_fold = 10\n",
    "predict_mode = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100]) tensor([[ 0.0633, -0.1828, -0.1010,  0.1154,  0.0248,  0.2018, -0.0248,  0.1244,\n",
      "          0.2477,  0.1866,  0.1078,  0.2721,  0.3446,  0.3025,  0.3193,  0.0182,\n",
      "          0.4350,  0.2556,  0.2274,  0.0851,  0.1164,  0.1907,  0.1009,  0.0985,\n",
      "          0.2254,  0.4081,  0.0429,  0.0757, -0.0316,  0.2798,  0.4592,  0.4829,\n",
      "          0.4250,  0.3467,  0.3093,  0.0192,  0.0951,  0.0831,  0.0982, -0.0779,\n",
      "         -0.1436, -0.3270, -0.1693, -0.3200, -0.3753, -0.2109, -0.3879, -0.3733,\n",
      "         -0.5053, -0.6190, -0.6050, -0.5224, -0.6313, -0.5602, -0.4642, -0.4588,\n",
      "         -0.3159, -0.4049, -0.0823, -0.0616,  0.0677,  0.1508,  0.1642,  0.2318,\n",
      "          0.0893,  0.1577,  0.0687,  0.1511, -0.0586, -0.0329, -0.0433, -0.0052,\n",
      "         -0.1156, -0.1102,  0.0600,  0.1076,  0.1307,  0.2685,  0.1922,  0.2164,\n",
      "          0.0936, -0.1973, -0.1023, -0.1345, -0.2304, -0.3110, -0.1868, -0.1859,\n",
      "         -0.0738, -0.0461, -0.0772,  0.0519,  0.0598, -0.0221,  0.0557,  0.1445,\n",
      "          0.1272,  0.0415,  0.0344,  0.0581]])\n",
      "quant:  tensor(0.1941)\n",
      "Compare two result\n",
      "Adapt  tensor([0.2018, 0.2477, 0.2721, 0.3446, 0.3025, 0.3193, 0.4350, 0.2556, 0.2274,\n",
      "        0.2254, 0.4081, 0.2798, 0.4592, 0.4829, 0.4250, 0.3467, 0.3093, 0.2318,\n",
      "        0.2685, 0.2164])\n",
      "Auto  [0.20177093 0.24770012 0.27208972 0.34458488 0.30250648 0.31929737\n",
      " 0.4350017  0.2556489  0.227366   0.22541913 0.40814418 0.27982464\n",
      " 0.45915833 0.48286587 0.42504984 0.3467408  0.30927786 0.23179631\n",
      " 0.26851955 0.21636923]\n"
     ]
    }
   ],
   "source": [
    "### torch adaptive test\n",
    "bs,ch,seqlen = 1,1,100\n",
    "signal = torch.randn(bs,seqlen,ch)\n",
    "#print(signal)\n",
    "windowed_sig = torch.nn.functional.avg_pool1d(signal.view(1,1,seqlen),kernel_size=10, stride=1, padding=5,count_include_pad=False).view(1,-1)[:,:seqlen]\n",
    "print(windowed_sig.shape,windowed_sig)\n",
    "quant_score = torch.quantile(windowed_sig[0],0.8)\n",
    "print('quant: ',quant_score)\n",
    "#keep adapt ways\n",
    "select_windows = (windowed_sig[0] >= quant_score).nonzero(as_tuple=True)[0].detach().cpu().numpy()\n",
    "#select_windows = select_windows + 10 // 2\n",
    "#keep auto ways\n",
    "passed_windows = []\n",
    "for x in range(100):\n",
    "    x1 = np.clip(x - 10 // 2, 0, seqlen)\n",
    "    x2 = np.clip(x + 10 // 2, 0, seqlen)\n",
    "    reg_mean = signal[0,x1: x2].mean()\n",
    "    if reg_mean >= quant_score:\n",
    "        passed_windows.append(reg_mean)\n",
    "passed_windows = np.array(passed_windows)\n",
    "print('Compare two result')\n",
    "print('Adapt ',windowed_sig[0,select_windows])\n",
    "print('Auto ',passed_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = np.array([0,1,2,3,3,6,4,6,6,6,6,6,6,2,2,1,3,5,5,5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test_dataset')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95b144beeb3a8d2cb1668ff3b47565577348e2e12c220d1ae8894fe6da6fc965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
